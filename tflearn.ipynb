{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tflearn\\data_utils.py\u001b[0m in \u001b[0;36mdirectory_to_samples\u001b[0;34m(directory, flags, filter_channel)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Python 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'next'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f60fe055a4dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m build_hdf5_image_dataset(target_path='image', image_shape=(256, 256), mode='folder',\n\u001b[1;32m     10\u001b[0m                          \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dataset.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                          normalize=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;31m# Load HDF5 dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tflearn\\data_utils.py\u001b[0m in \u001b[0;36mbuild_hdf5_image_dataset\u001b[0;34m(target_path, image_shape, output_path, mode, categorical_labels, normalize, grayscale, files_extension, chunks)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'folder'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         images, labels = directory_to_samples(target_path,\n\u001b[0;32m--> 375\u001b[0;31m                                               flags=files_extension)\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tflearn\\data_utils.py\u001b[0m in \u001b[0;36mdirectory_to_samples\u001b[0;34m(directory, flags, filter_channel)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mc_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Build a HDF5 dataset (only required once)\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn.datasets.mnist as mnist\n",
    "import numpy as np\n",
    "from tflearn.data_utils import build_hdf5_image_dataset\n",
    "build_hdf5_image_dataset(target_path='image', image_shape=(256, 256), mode='folder',\n",
    "                         output_path='dataset.h5', categorical_labels=True,\n",
    "                         normalize=True)\n",
    "\n",
    "# Load HDF5 dataset\n",
    "import h5py\n",
    "h5f = h5py.File('dataset.h5', 'r')\n",
    "X_D = h5f['X']\n",
    "Y_D = h5f['Y']\n",
    "\n",
    "# Building convolutional convnet\n",
    "convnet = input_data([None, 256, 256, 3])\n",
    "# http://tflearn.org/layers/conv/\n",
    "# http://tflearn.org/activations/\n",
    "convnet = conv_2d(convnet, 16, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "#convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "#convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "convnet = fully_connected(convnet, 128, activation='relu')\n",
    "#convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 55, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet)\n",
    "\n",
    "model.fit(X_D, Y_D, n_epoch=500, validation_set=(X_D, Y_D), show_metric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2799  | total loss: \u001b[1m\u001b[32m4.00249\u001b[0m\u001b[0m | time: 2.292s\n",
      "| Adam | epoch: 200 | loss: 4.00249 - acc: 0.0475 -- iter: 832/838\n",
      "Training Step: 2800  | total loss: \u001b[1m\u001b[32m4.00281\u001b[0m\u001b[0m | time: 3.541s\n",
      "| Adam | epoch: 200 | loss: 4.00281 - acc: 0.0444 | val_loss: 4.00365 - val_acc: 0.0346 -- iter: 838/838\n",
      "--\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
